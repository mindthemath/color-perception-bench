models:
  nomic-embed-v1.5:
    provider_type: local
    base_url: http://localhost:8080
    text_endpoint:
      path: /txt/query
      method: POST
      input_field: input
      output_field: embedding
    image_endpoint:
      path: /img/embed
      method: POST
      input_field: input
      output_field: embedding
    user_batch_size: 1

  # Voyage AI - Best commercial option for cross-modal (same embedding space)
  # Sign up: https://www.voyageai.com/ → Dashboard → API Keys
  voyage-multimodal-3:
    provider_type: openai_compatible
    base_url: https://api.voyageai.com/v1
    text_endpoint:
      path: /embeddings
      method: POST
      input_field: input
      output_field: data[0].embedding
      model: voyage-multimodal-3
    image_endpoint:
      path: /embeddings
      method: POST
      input_field: input
      output_field: data[0].embedding
      model: voyage-multimodal-3
    api_key_env: VOYAGE_API_KEY
    user_batch_size: 32

  # Jina AI - Latest CLIP model (Oct 2024)
  # Sign up: https://jina.ai/ → Settings → API Tokens (free tier available)
  jina-clip-v2:
    provider_type: openai_compatible
    base_url: https://api.jina.ai/v1
    text_endpoint:
      path: /embeddings
      method: POST
      input_field: input
      output_field: data[0].embedding
      model: jina-clip-v2
      wrap_input: true
      input_wrapper_key: text
    image_endpoint:
      path: /embeddings
      method: POST
      input_field: input
      output_field: data[0].embedding
      model: jina-clip-v2
      wrap_input: true
      input_wrapper_key: image
    api_key_env: JINA_API_KEY
    user_batch_size: 16
    rate_limit_delay: 0.8  # 100 RPM free tier = ~0.6s between requests

  # Jina AI - Latest multimodal embeddings (Jan 2025)
  # Same API key as jina-clip-v2, supports text-matching task
  jina-embeddings-v4:
    provider_type: openai_compatible
    base_url: https://api.jina.ai/v1
    text_endpoint:
      path: /embeddings
      method: POST
      input_field: input
      output_field: data[0].embedding
      model: jina-embeddings-v4
      wrap_input: true
      input_wrapper_key: text
    image_endpoint:
      path: /embeddings
      method: POST
      input_field: input
      output_field: data[0].embedding
      model: jina-embeddings-v4
      wrap_input: true
      input_wrapper_key: image
    api_key_env: JINA_API_KEY
    task: text-matching
    user_batch_size: 16
    rate_limit_delay: 0.8  # 100 RPM free tier = ~0.6s between requests

  # BAAI - BGE-VL (Local Docker)
  bge-vl-base:
    provider_type: local
    base_url: http://localhost:8001
    text_endpoint:
      path: /txt/embed
      method: POST
      input_field: input
      output_field: embedding
    image_endpoint:
      path: /img/embed
      method: POST
      input_field: input
      output_field: embedding
    user_batch_size: 1

  # Google - SigLIP 2 (Local Docker)
  siglip2-so400m:
    provider_type: local
    base_url: http://localhost:8002
    text_endpoint:
      path: /txt/embed
      method: POST
      input_field: input
      output_field: embedding
    image_endpoint:
      path: /img/embed
      method: POST
      input_field: input
      output_field: embedding
    user_batch_size: 1

  # Qwen - Qwen3-VL-Embedding (Local Docker, smallest variant)
  qwen3-vl-embed-2b:
    provider_type: local
    base_url: http://localhost:8003
    text_endpoint:
      path: /txt/embed
      method: POST
      input_field: input
      output_field: embedding
    image_endpoint:
      path: /img/embed
      method: POST
      input_field: input
      output_field: embedding
    user_batch_size: 1
